{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e7ef802",
   "metadata": {},
   "source": [
    "\n",
    "# Part 4 — Real‑Time Object Detection (YOLOv8, SSD, OpenCV DNN)\n",
    "\n",
    "**Course:** CV Lab II — Machine Learning with OpenCV  \n",
    "**Author:** _Tsion Bizuayehu  \n",
    "**Last updated:** 2025-09-07 17:48 UTC  \n",
    "\n",
    "In this notebook you will implement and compare **three** real-time object detection pipelines:\n",
    "\n",
    "1. **YOLOv8 (Ultralytics API)** — easiest to start, great accuracy/speed.  \n",
    "2. **MobileNet‑SSD (Caffe) via OpenCV DNN** — lightweight baseline.  \n",
    "3. **YOLOv8 (ONNX) via OpenCV DNN** — framework‑agnostic deployment path.\n",
    "\n",
    "You will run them on images, webcam, and videos; and benchmark FPS.\n",
    "\n",
    "**What you’ll learn**\n",
    "- Set up environment, verify CUDA, and manage models\n",
    "- Run YOLOv8 with Ultralytics in a few lines\n",
    "- Run MobileNet‑SSD with OpenCV DNN\n",
    "- Export YOLOv8 → ONNX and run with OpenCV DNN (post‑processing + NMS)\n",
    "- Measure FPS and save annotated videos\n",
    "\n",
    "_Tip:_ If you’re in Jupyter **Lab/Notebook**, windows opened by OpenCV (`cv2.imshow`) may appear as OS windows.\n",
    "Press **q** in the window to quit loops.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5778d8",
   "metadata": {},
   "source": [
    "\n",
    "## 0. Environment Setup\n",
    "\n",
    "Run the next cell to install the required packages.  \n",
    "If you're offline, install these with `pip` first:\n",
    "\n",
    "```txt\n",
    "opencv-python\n",
    "ultralytics\n",
    "numpy\n",
    "onnx\n",
    "onnxruntime  # for ONNX CPU\n",
    "onnxruntime-gpu # (optional) for ONNX CUDA\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77bf6d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: opencv-python in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (8.3.195)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: onnx in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (1.19.0)\n",
      "Requirement already satisfied: onnxruntime in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (1.22.1)\n",
      "Requirement already satisfied: onnxruntime-gpu in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (1.22.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (10.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (2.7.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (0.22.0)\n",
      "Requirement already satisfied: psutil in c:\\programdata\\anaconda3\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: polars in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (1.33.0)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (2.0.17)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from onnx) (4.25.3)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from onnx) (4.11.0)\n",
      "Requirement already satisfied: ml_dtypes in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from onnx) (0.4.1)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime) (25.2.10)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from onnxruntime) (24.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from onnxruntime) (1.14.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.8.0->ultralytics) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\tsion\\appdata\\roaming\\python\\python312\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If needed, uncomment to install (internet required)\n",
    "# !pip install -U pip\n",
    "!pip install opencv-python ultralytics numpy onnx onnxruntime onnxruntime-gpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b61778e",
   "metadata": {},
   "source": [
    "## 1. Imports & Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6db82a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.7\n",
      "OpenCV: 4.11.0\n",
      "PyTorch: 2.7.0+cpu\n",
      "Ultralytics: 8.3.195\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys, time, os, math, json, pathlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    torch_version = torch.__version__\n",
    "except Exception as e:\n",
    "    torch, torch_version = None, None\n",
    "\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    import ultralytics\n",
    "    yolo_version = ultralytics.__version__\n",
    "except Exception as e:\n",
    "    YOLO, yolo_version = None, None\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"PyTorch:\", torch_version)\n",
    "print(\"Ultralytics:\", yolo_version)\n",
    "\n",
    "if torch is not None:\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81581cbc",
   "metadata": {},
   "source": [
    "## 2. Utility Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15b8f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "def ensure_dir(p: str):\n",
    "    Path(p).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def put_label(img, text, org, color=(0, 255, 0)):\n",
    "    cv2.putText(img, text, org, cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2, cv2.LINE_AA)\n",
    "\n",
    "def fps_counter():\n",
    "    prev = time.time()\n",
    "    while True:\n",
    "        now = time.time()\n",
    "        fps = 1.0 / (now - prev) if now != prev else 0.0\n",
    "        prev = now\n",
    "        yield fps\n",
    "\n",
    "# COCO 80 classes (YOLOv8 default)\n",
    "COCO_NAMES = [\n",
    "    \"person\",\"bicycle\",\"car\",\"motorcycle\",\"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\"traffic light\",\n",
    "    \"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\"dog\",\"horse\",\"sheep\",\"cow\",\n",
    "    \"elephant\",\"bear\",\"zebra\",\"giraffe\",\"backpack\",\"umbrella\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\n",
    "    \"skis\",\"snowboard\",\"sports ball\",\"kite\",\"baseball bat\",\"baseball glove\",\"skateboard\",\"surfboard\",\n",
    "    \"tennis racket\",\"bottle\",\"wine glass\",\"cup\",\"fork\",\"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\n",
    "    \"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\"cake\",\"chair\",\"couch\",\n",
    "    \"potted plant\",\"bed\",\"dining table\",\"toilet\",\"tv\",\"laptop\",\"mouse\",\"remote\",\"keyboard\",\"cell phone\",\n",
    "    \"microwave\",\"oven\",\"toaster\",\"sink\",\"refrigerator\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\n",
    "    \"hair drier\",\"toothbrush\"\n",
    "]\n",
    "\n",
    "# Letterbox resize like YOLO for ONNX -> OpenCV pipeline\n",
    "def letterbox(img, new_shape=(640, 640), color=(114, 114, 114), auto=False, scaleFill=False, scaleup=True):\n",
    "    shape = img.shape[:2]  # current shape [height, width]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # Scale ratio (new / old)\n",
    "    r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "    if not scaleup:\n",
    "        r = min(r, 1.0)\n",
    "\n",
    "    # Compute padding\n",
    "    new_unpad = (int(round(shape[1] * r)), int(round(shape[0] * r)))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # width, height padding\n",
    "    if auto:\n",
    "        dw, dh = np.mod(dw, 64), np.mod(dh, 64)  # 64-pt stride-multiple padding\n",
    "    dw /= 2; dh /= 2\n",
    "\n",
    "    # resize\n",
    "    if shape[::-1] != new_unpad:\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "    top, bottom = int(round(dh-0.1)), int(round(dh+0.1))\n",
    "    left, right = int(round(dw-0.1)), int(round(dw+0.1))\n",
    "    img = cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)\n",
    "    return img, r, (dw, dh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572a7d5",
   "metadata": {},
   "source": [
    "\n",
    "## 3. YOLOv8 — Ultralytics API\n",
    "\n",
    "### 3.1 Inference on a single image\n",
    "Put a test image under `data/images/your_image.jpg` and set the path below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fbdd22c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/images/faces/face_sample.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUltralytics not installed. Run the pip cell above.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(model_name)  \u001b[38;5;66;03m# auto-downloads weights on first use\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage not found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Place an image and re-run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m model(img, conf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\utils\\patches.py:35\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    Read an image from a file with multilanguage filename support.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m        >>> img = imread(\"path/to/image.jpg\", cv2.IMREAD_GRAYSCALE)\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m     file_bytes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(filename, np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m     37\u001b[0m         success, frames \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimdecodemulti(file_bytes, cv2\u001b[38;5;241m.\u001b[39mIMREAD_UNCHANGED)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/images/faces/face_sample.jpg'"
     ]
    }
   ],
   "source": [
    "\n",
    "ensure_dir(\"/images/faces/\"); ensure_dir(\"outputs\")\n",
    "\n",
    "image_path = \"/images/faces/face_sample.jpg\"  # <-- change to your image\n",
    "model_name = \"yolov8n.pt\"           # 'n' is fast; try 's','m' for accuracy\n",
    "\n",
    "if YOLO is None:\n",
    "    raise RuntimeError(\"Ultralytics not installed. Run the pip cell above.\")\n",
    "\n",
    "model = YOLO(model_name)  # auto-downloads weights on first use\n",
    "img = cv2.imread(image_path)\n",
    "assert img is not None, f\"Image not found at {image_path}. Place an image and re-run.\"\n",
    "\n",
    "results = model(img, conf=0.5)\n",
    "# Plot and save\n",
    "for i, r in enumerate(results):\n",
    "    plotted = r.plot()\n",
    "    out_path = f\"outputs/yolov8_image_{i}.jpg\"\n",
    "    cv2.imwrite(out_path, plotted)\n",
    "    print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f362742-34fd-4455-99e7-f41a8623e25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faces directory exists? True\n",
      "files inside faces/:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"faces directory exists?\", os.path.isdir(\"images/faces/\"))\n",
    "print(\"files inside faces/:\" if os.path.isdir(\"images/faces/\") else \"no faces/ folder\")\n",
    "\n",
    "if os.path.isdir(\"faces\"):\n",
    "    print(os.listdir(\"faces\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8159c16",
   "metadata": {},
   "source": [
    "\n",
    "### 3.2 Webcam / Video inference (press **q** to quit)\n",
    "\n",
    "- Set `source = 0` for default webcam, or provide a video path.\n",
    "- Set `save_vid = True` to write an output video under `outputs/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94120ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source = 0  # 0 = default webcam; or e.g., \"data/videos/input.mp4\"\n",
    "save_vid = True\n",
    "out_path = \"outputs/yolov8_ultralytics_out.mp4\"\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# If source is a file, grab size from the file. If webcam, use runtime framesize.\n",
    "cap = cv2.VideoCapture(source)\n",
    "assert cap.isOpened(), f\"Cannot open source: {source}\"\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 640\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 480\n",
    "fps_out = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "\n",
    "writer = None\n",
    "if save_vid:\n",
    "    ensure_dir(\"outputs\")\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(out_path, fourcc, fps_out, (w, h))\n",
    "\n",
    "for r in model.track(source=source, show=True, stream=True, conf=0.5):\n",
    "    frame = r.plot()\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "if writer is not None:\n",
    "    writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done. Saved to:\", out_path if save_vid else \"(not saved)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e93f8e",
   "metadata": {},
   "source": [
    "\n",
    "## 4. MobileNet‑SSD — OpenCV DNN\n",
    "\n",
    "We'll use the classic Caffe MobileNet‑SSD pretrained on VOC.  \n",
    "The next cell will **download** the model files (internet required). If you're offline, manually place them under `models/ssd/`:\n",
    "\n",
    "- `MobileNetSSD_deploy.prototxt`\n",
    "- `MobileNetSSD_deploy.caffemodel`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ensure_dir(\"models/ssd\")\n",
    "import urllib.request\n",
    "\n",
    "files = {\n",
    "    \"models/ssd/MobileNetSSD_deploy.prototxt\":\n",
    "        \"https://raw.githubusercontent.com/chuanqi305/MobileNet-SSD/master/MobileNetSSD_deploy.prototxt\",\n",
    "    \"models/ssd/MobileNetSSD_deploy.caffemodel\":\n",
    "        \"https://github.com/chuanqi305/MobileNet-SSD/raw/master/MobileNetSSD_deploy.caffemodel\",\n",
    "}\n",
    "\n",
    "for dst, url in files.items():\n",
    "    if not Path(dst).exists():\n",
    "        try:\n",
    "            print(\"Downloading\", url, \"->\", dst)\n",
    "            urllib.request.urlretrieve(url, dst)\n",
    "        except Exception as e:\n",
    "            print(\"Could not download:\", url, \"| Error:\", e)\n",
    "    else:\n",
    "        print(\"Exists:\", dst)\n",
    "\n",
    "# VOC 20 classes used by the original MobileNet-SSD\n",
    "VOC_CLASSES = [\"background\",\"aeroplane\",\"bicycle\",\"bird\",\"boat\",\"bottle\",\"bus\",\"car\",\"cat\",\"chair\",\n",
    "               \"cow\",\"diningtable\",\"dog\",\"horse\",\"motorbike\",\"person\",\"pottedplant\",\"sheep\",\"sofa\",\n",
    "               \"train\",\"tvmonitor\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575ffbca",
   "metadata": {},
   "source": [
    "### 4.1 SSD — Image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606dbaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proto = \"models/ssd/MobileNetSSD_deploy.prototxt\"\n",
    "caffe = \"models/ssd/MobileNetSSD_deploy.caffemodel\"\n",
    "net = cv2.dnn.readNetFromCaffe(proto, caffe)\n",
    "\n",
    "img_path = \"data/images/test.jpg\"  # reuse your image\n",
    "img = cv2.imread(img_path); assert img is not None, \"Place an image at data/images/test.jpg\"\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(img, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "net.setInput(blob)\n",
    "dets = net.forward()\n",
    "\n",
    "for i in range(dets.shape[2]):\n",
    "    conf = float(dets[0, 0, i, 2])\n",
    "    if conf >= 0.5:\n",
    "        cls_id = int(dets[0, 0, i, 1])\n",
    "        x1, y1, x2, y2 = (dets[0, 0, i, 3:7] * np.array([w, h, w, h])).astype(int)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        label = f\"{VOC_CLASSES[cls_id]} {conf:.2f}\"\n",
    "        put_label(img, label, (x1, max(0, y1-6)))\n",
    "\n",
    "out_path = \"outputs/ssd_image.jpg\"\n",
    "ensure_dir(\"outputs\")\n",
    "cv2.imwrite(out_path, img)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33b3bd0",
   "metadata": {},
   "source": [
    "### 4.2 SSD — Webcam/Video (press **q** to quit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57147829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source = 0  # webcam or path to mp4\n",
    "cap = cv2.VideoCapture(source)\n",
    "assert cap.isOpened(), f\"Cannot open source: {source}\"\n",
    "\n",
    "writer = None; out_path = \"outputs/ssd_out.mp4\"\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 640\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 480\n",
    "fps_out = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "writer = cv2.VideoWriter(out_path, fourcc, fps_out, (w, h))\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(\"models/ssd/MobileNetSSD_deploy.prototxt\",\n",
    "                               \"models/ssd/MobileNetSSD_deploy.caffemodel\")\n",
    "\n",
    "fps_gen = fps_counter()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob)\n",
    "    dets = net.forward()\n",
    "\n",
    "    for i in range(dets.shape[2]):\n",
    "        conf = float(dets[0, 0, i, 2])\n",
    "        if conf >= 0.5:\n",
    "            cls_id = int(dets[0, 0, i, 1])\n",
    "            hF, wF = frame.shape[:2]\n",
    "            x1, y1, x2, y2 = (dets[0, 0, i, 3:7] * np.array([wF, hF, wF, hF])).astype(int)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            put_label(frame, f\"{VOC_CLASSES[cls_id]}\", (x1, max(0, y1-6)))\n",
    "\n",
    "    fps = next(fps_gen)\n",
    "    put_label(frame, f\"FPS: {fps:.1f}\", (10, 30), (0, 255, 255))\n",
    "\n",
    "    writer.write(frame)\n",
    "    cv2.imshow(\"SSD DNN\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release(); writer.release(); cv2.destroyAllWindows()\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3c151",
   "metadata": {},
   "source": [
    "\n",
    "## 5. YOLOv8 → ONNX (export) and OpenCV DNN\n",
    "\n",
    "### 5.1 Export weights to ONNX\n",
    "Run this once to generate `yolov8n.onnx` in `models/yolo/`. You need Ultralytics installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ensure_dir(\"models/yolo\")\n",
    "if YOLO is None:\n",
    "    raise RuntimeError(\"Ultralytics not installed. Run the pip cell above.\")\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "onnx_path = \"models/yolo/yolov8n.onnx\"\n",
    "model.export(format=\"onnx\", opset=12, simplify=True, imgsz=640, dynamic=False, half=False, device=None, name=onnx_path)\n",
    "print(\"Exported:\", onnx_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f949b9",
   "metadata": {},
   "source": [
    "### 5.2 OpenCV DNN inference (ONNX) — helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c12394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def yolo_postprocess(outputs: np.ndarray, img_shape, conf_thres=0.25, iou_thres=0.45):\n",
    "    # outputs: (batch, num, 85) or (num, 85); we assume (1, N, 85)\n",
    "    if outputs.ndim == 3:\n",
    "        outputs = outputs[0]  # (N, 85)\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    class_ids = []\n",
    "\n",
    "    h, w = img_shape[:2]\n",
    "    for i in range(outputs.shape[0]):\n",
    "        row = outputs[i]\n",
    "        obj = row[4] if row.shape[0] >= 6 else 1.0  # compatibility\n",
    "        class_scores = row[5:]\n",
    "        if class_scores.size == 0:\n",
    "            # Some exports pack x,y,w,h + class confs (no obj)\n",
    "            class_scores = row[4:]\n",
    "            obj = 1.0\n",
    "        cls_id = int(np.argmax(class_scores))\n",
    "        conf = class_scores[cls_id] * obj\n",
    "        if conf >= conf_thres:\n",
    "            # xywh -> xyxy in original image scale is handled outside; here we keep raw\n",
    "            boxes.append(row[:4])\n",
    "            scores.append(float(conf))\n",
    "            class_ids.append(cls_id)\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        return [], [], []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    scores = np.array(scores)\n",
    "\n",
    "    # NMS pre: convert from cx,cy,w,h to x1,y1,x2,y2 (in the resized image space 640x640)\n",
    "    cx, cy, bw, bh = boxes[:,0], boxes[:,1], boxes[:,2], boxes[:,3]\n",
    "    x1 = cx - bw/2; y1 = cy - bh/2; x2 = cx + bw/2; y2 = cy + bh/2\n",
    "    boxes_xyxy = np.stack([x1, y1, x2, y2], axis=1)\n",
    "\n",
    "    # OpenCV NMS\n",
    "    idxs = cv2.dnn.NMSBoxes(\n",
    "        bboxes=boxes_xyxy.tolist(),\n",
    "        scores=scores.tolist(),\n",
    "        score_threshold=conf_thres,\n",
    "        nms_threshold=iou_thres\n",
    "    )\n",
    "    idxs = idxs.flatten().tolist() if len(idxs) > 0 else []\n",
    "    return boxes_xyxy[idxs], scores[idxs].tolist(), [class_ids[i] for i in idxs]\n",
    "\n",
    "def scale_coords(resized_shape, boxes_xyxy, original_shape, ratio_pad):\n",
    "    # Map boxes from letterboxed image space back to original image space\n",
    "    (_, _), (dw, dh) = ((0,0), ratio_pad)\n",
    "    gain = min(resized_shape[0] / original_shape[0], resized_shape[1] / original_shape[1])\n",
    "    boxes = boxes_xyxy.copy()\n",
    "    boxes[:, [0,2]] -= dw*2\n",
    "    boxes[:, [1,3]] -= dh*2\n",
    "    boxes[:, :4] /= gain\n",
    "    # clip\n",
    "    h, w = original_shape[:2]\n",
    "    boxes[:, [0,2]] = boxes[:, [0,2]].clip(0, w-1)\n",
    "    boxes[:, [1,3]] = boxes[:, [1,3]].clip(0, h-1)\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996ee09",
   "metadata": {},
   "source": [
    "### 5.3 ONNX — Image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onnx_path = \"models/yolo/yolov8n.onnx\"\n",
    "net = cv2.dnn.readNetFromONNX(onnx_path)\n",
    "\n",
    "img_path = \"data/images/test.jpg\"\n",
    "img0 = cv2.imread(img_path); assert img0 is not None, \"Place an image at data/images/test.jpg\"\n",
    "img, r, (dw, dh) = letterbox(img0, (640, 640))\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255.0, (640, 640), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "out = net.forward()  # shape: (1, N, 85) for YOLOv8\n",
    "\n",
    "boxes_xyxy, scores, class_ids = yolo_postprocess(out, img.shape, conf_thres=0.35, iou_thres=0.5)\n",
    "if len(boxes_xyxy):\n",
    "    # scale back to original image\n",
    "    boxes_xyxy = scale_coords((640,640), boxes_xyxy, img0.shape, (dw, dh)).astype(int)\n",
    "    for (x1,y1,x2,y2), s, cid in zip(boxes_xyxy, scores, class_ids):\n",
    "        cv2.rectangle(img0, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "        cls = COCO_NAMES[cid] if cid < len(COCO_NAMES) else str(cid)\n",
    "        put_label(img0, f\"{cls} {s:.2f}\", (x1, max(0, y1-6)))\n",
    "\n",
    "ensure_dir(\"outputs\")\n",
    "out_path = \"outputs/yolov8_onnx_image.jpg\"\n",
    "cv2.imwrite(out_path, img0)\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffedb5",
   "metadata": {},
   "source": [
    "### 5.4 ONNX — Webcam/Video (press **q** to quit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e723690",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source = 0  # webcam or path to mp4\n",
    "cap = cv2.VideoCapture(source)\n",
    "assert cap.isOpened(), f\"Cannot open source: {source}\"\n",
    "out_path = \"outputs/yolov8_onnx_out.mp4\"\n",
    "\n",
    "w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) or 640\n",
    "h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)) or 480\n",
    "fps_out = cap.get(cv2.CAP_PROP_FPS) or 30\n",
    "\n",
    "net = cv2.dnn.readNetFromONNX(\"models/yolo/yolov8n.onnx\")\n",
    "\n",
    "writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps_out, (w, h))\n",
    "fps_gen = fps_counter()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "\n",
    "    img, r, (dw, dh) = letterbox(frame, (640, 640))\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (640, 640), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()\n",
    "\n",
    "    boxes_xyxy, scores, class_ids = yolo_postprocess(out, img.shape, conf_thres=0.35, iou_thres=0.5)\n",
    "    if len(boxes_xyxy):\n",
    "        boxes_xyxy = scale_coords((640,640), boxes_xyxy, frame.shape, (dw, dh)).astype(int)\n",
    "        for (x1,y1,x2,y2), s, cid in zip(boxes_xyxy, scores, class_ids):\n",
    "            cv2.rectangle(frame, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "            cls = COCO_NAMES[cid] if cid < len(COCO_NAMES) else str(cid)\n",
    "            put_label(frame, f\"{cls} {s:.2f}\", (x1, max(0, y1-6)))\n",
    "\n",
    "    fps = next(fps_gen)\n",
    "    put_label(frame, f\"FPS: {fps:.1f}\", (10, 30), (0, 255, 255))\n",
    "\n",
    "    writer.write(frame)\n",
    "    cv2.imshow(\"YOLOv8 ONNX (OpenCV DNN)\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release(); writer.release(); cv2.destroyAllWindows()\n",
    "print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed556c7",
   "metadata": {},
   "source": [
    "## 6. Simple FPS Benchmark (Image batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import glob\n",
    "\n",
    "# Put a few images under data/images/\n",
    "imgs = [cv2.imread(p) for p in sorted(glob.glob(\"data/images/*\"))[:8]]\n",
    "imgs = [im for im in imgs if im is not None]\n",
    "assert imgs, \"Add some images into data/images/\"\n",
    "\n",
    "# YOLOv8 (Ultralytics) single-image timing\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "t0 = time.time()\n",
    "for im in imgs:\n",
    "    _ = model.predict(source=im, conf=0.5, verbose=False)\n",
    "t1 = time.time()\n",
    "print(f\"YOLOv8 Ultralytics: {(len(imgs)/(t1-t0)):.2f} FPS (images/sec)\")\n",
    "\n",
    "# SSD (OpenCV) timing\n",
    "net = cv2.dnn.readNetFromCaffe(\"models/ssd/MobileNetSSD_deploy.prototxt\",\n",
    "                               \"models/ssd/MobileNetSSD_deploy.caffemodel\")\n",
    "t0 = time.time()\n",
    "for im in imgs:\n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(im, (300, 300)), 0.007843, (300, 300), 127.5)\n",
    "    net.setInput(blob); _ = net.forward()\n",
    "t1 = time.time()\n",
    "print(f\"MobileNet-SSD DNN: {(len(imgs)/(t1-t0)):.2f} FPS (images/sec)\")\n",
    "\n",
    "# YOLOv8 ONNX (OpenCV DNN) timing\n",
    "net = cv2.dnn.readNetFromONNX(\"models/yolo/yolov8n.onnx\")\n",
    "t0 = time.time()\n",
    "for im in imgs:\n",
    "    img, r, (dw, dh) = letterbox(im, (640, 640))\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (640, 640), swapRB=True, crop=False)\n",
    "    net.setInput(blob); _ = net.forward()\n",
    "t1 = time.time()\n",
    "print(f\"YOLOv8 ONNX (DNN): {(len(imgs)/(t1-t0)):.2f} FPS (images/sec)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbef1fb",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Wrap‑Up & Next Steps\n",
    "\n",
    "- Try different YOLOv8 sizes: `yolov8s.pt`, `yolov8m.pt` for accuracy vs speed\n",
    "- Replace COCO names with your dataset and fine‑tune a custom model (Ultralytics `model.train(...)`)\n",
    "- Compare FPS on CPU vs GPU (Torch vs OpenCV DNN vs ONNX Runtime)\n",
    "\n",
    "**Suggested Exercises**\n",
    "1. Replace YOLOv8 with YOLOv5 or YOLOv7 and compare FPS/accuracy.\n",
    "2. Benchmark SSD vs YOLOv8 on your machine (CPU/GPU) and record results in a table.\n",
    "3. Train a YOLO model on a small custom dataset and test in real‑time.\n",
    "4. Use OpenCV DNN to run COCO-trained ONNX **without** Ultralytics API (done above!).\n",
    "\n",
    "**Notes**\n",
    "- This notebook follows the CV Lab manual’s Chapter 11 outline (Real-Time Object Detection).  \n",
    "- If `cv2.imshow` windows do not appear in your environment, run in a local Python script or enable GUI backend.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5b9c0-158c-4dc0-ba08-0108dfebfe31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
