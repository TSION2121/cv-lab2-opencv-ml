{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2b03daf",
   "metadata": {},
   "source": [
    "# Part 4 â€” Real-Time Object Detection (YOLOv8, SSD, OpenCV DNN)\n",
    "\n",
    "**Jupyter-Compatible Version (Windows + Anaconda)**\n",
    "\n",
    "Author: Tsion Bizuayehu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e692c92-91f0-4dbd-b691-2b761b626e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uninstall CPU-only PyTorch\n",
    "# !pip uninstall -y torch torchvision torchaudio\n",
    "\n",
    "# Install GPU-enabled PyTorch (example for CUDA 12.1)\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536fa85-141c-4b64-99ca-3c9f39e25f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless numpy matplotlib ultralytics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1577e83-3639-4b5d-87d5-7a6900e60ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import urllib\n",
    "\n",
    "# Helper to display image in Jupyter\n",
    "def show_frame(frame, title=\"Frame\"):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Load YOLOv8n (small model, fast)\n",
    "yolo_model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Download test image\n",
    "url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "arr = np.asarray(bytearray(urllib.request.urlopen(url).read()), dtype=np.uint8)\n",
    "frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Resize image to reduce CPU load\n",
    "height, width = frame.shape[:2]\n",
    "new_width = 640  # smaller width\n",
    "new_height = int(height * new_width / width)\n",
    "frame_small = cv2.resize(frame, (new_width, new_height))\n",
    "\n",
    "# Run YOLO inference on CPU with smaller image\n",
    "results = yolo_model.predict(frame_small, imgsz=320)  # smaller size for CPU\n",
    "\n",
    "# Safely display result in Jupyter\n",
    "annotated_frame = results[0].plot()  # this is smaller because of imgsz=320\n",
    "show_frame(annotated_frame, title=\"YOLOv8 Detection\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import ultralytics\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"OpenCV:\", cv2.__version__)\n",
    "print(\"PyTorch:\", torch.__version__)\n",
    "print(\"Ultralytics:\", ultralytics.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "# Jupyter-friendly image display\n",
    "def show_frame(frame, title=\"Frame\"):\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(frame_rgb)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff8135",
   "metadata": {},
   "source": [
    "## 1. YOLOv8 (Ultralytics API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ab2703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "arr = np.asarray(bytearray(urllib.request.urlopen(url).read()), dtype=np.uint8)\n",
    "frame = cv2.imdecode(arr, cv2.IMREAD_COLOR)\n",
    "\n",
    "# Resize to smaller width (e.g., 640)\n",
    "frame_small = cv2.resize(frame, (640, int(frame.shape[0] * 640 / frame.shape[1])))\n",
    "\n",
    "results = yolo_model(frame_small)\n",
    "plt.imshow(results[0].plot()[:, :, ::-1])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ee900",
   "metadata": {},
   "source": [
    "## 2. MobileNet-SSD (OpenCV DNN, Caffe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcb7cc9-947c-46de-ac96-d10d1b7595b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"C:/Users/tsion/Downloads/cv-lab2-opencv-ml/part4-real-time-detection\"):\n",
    "    for f in files:\n",
    "        if \"prototxt\" in f.lower():\n",
    "            print(os.path.join(root, f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d87670-443a-4e6a-898c-d13c86d4a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxt = r\"C:\\Users\\tsion\\Downloads\\cv-lab2-opencv-ml\\part4-real-time-detection\\model\\ssd\\deploy.prototxt\"\n",
    "caffemodel = r\"C:\\Users\\tsion\\Downloads\\cv-lab2-opencv-ml\\part4-real-time-detection\\model\\ssd\\mobilenet_iter_73000.caffemodel\"\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt, caffemodel)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf652613-010a-4873-84cf-e1ec08a4493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, cv2\n",
    "\n",
    "BASE_DIR = os.path.dirname(os.path.abspath(\"__file__\"))  # notebook root\n",
    "\n",
    "prototxt = os.path.join(BASE_DIR, \"model\", \"ssd\", \"deploy.prototxt\")\n",
    "caffemodel = os.path.join(BASE_DIR, \"model\", \"ssd\", \"mobilenet_iter_73000.caffemodel\")\n",
    "\n",
    "print(\"Prototxt:\", prototxt)\n",
    "print(\"Caffe model:\", caffemodel)\n",
    "\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt, caffemodel)\n",
    "print(\"Model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0676e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. MobileNet-SSD (OpenCV DNN, Caffe)\n",
    "\n",
    "import os\n",
    "\n",
    "prototxt = \"deploy.prototxt\"\n",
    "caffemodel = \"mobilenet_iter_73000.caffemodel\"\n",
    "image_path = \"../images/faces/face_sample.jpg\"  # Corrected path\n",
    "\n",
    "# Safety checks\n",
    "assert os.path.exists(prototxt), f\"Missing {prototxt}\"\n",
    "assert os.path.exists(caffemodel), f\"Missing {caffemodel}\"\n",
    "assert os.path.exists(image_path), f\"Missing {image_path}\"\n",
    "\n",
    "# Load model\n",
    "net = cv2.dnn.readNetFromCaffe(prototxt, caffemodel)\n",
    "\n",
    "CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n",
    "           \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n",
    "           \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\",\n",
    "           \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread(image_path)\n",
    "assert image is not None, \"Image failed to load\"\n",
    "\n",
    "(h, w) = image.shape[:2]\n",
    "blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)),\n",
    "                             0.007843, (300, 300), 127.5)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# Draw results\n",
    "for i in range(detections.shape[2]):\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    if confidence > 0.5:\n",
    "        idx = int(detections[0, 0, i, 1])\n",
    "        box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "        (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "        label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n",
    "        cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "                      (0, 255, 0), 2)\n",
    "        cv2.putText(image, label, (startX, startY - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "show_frame(image, \"SSD Detection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845bb84",
   "metadata": {},
   "source": [
    "## 3. YOLOv8 (ONNX + OpenCV DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147e517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv8 exported to ONNX\n",
    "# Run once to export: yolo_model.export(format=\"onnx\")\n",
    "onnx_path = \"yolov8n.onnx\"\n",
    "net_onnx = cv2.dnn.readNetFromONNX(onnx_path)\n",
    "\n",
    "image = cv2.imread(\"test.jpg\")\n",
    "blob = cv2.dnn.blobFromImage(image, 1/255.0, (640, 640), swapRB=True, crop=False)\n",
    "net_onnx.setInput(blob)\n",
    "preds = net_onnx.forward()\n",
    "\n",
    "print(\"ONNX raw output shape:\", preds.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch_gpu)",
   "language": "python",
   "name": "pytorch_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
