{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a871e952-77c8-407d-9251-0b931dfb1362",
   "metadata": {},
   "source": [
    "# ðŸ§  Lab 3 â€“ Deep Learning Detection with ResNet\n",
    "\n",
    "This notebook demonstrates image classification using a pretrained ResNet-18 model from PyTorch. The input image is sourced from Hound Rack 3 and processed through a CNN to predict its class label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393bde01-0a81-4eec-a5b7-f6fe5542a8f6",
   "metadata": {},
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9b25cb0-36a9-4756-85f2-e329cdac96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8878d146-943e-4ba2-8f74-5ebdb2732240",
   "metadata": {},
   "source": [
    "## Load & Display Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0144d3b-c76d-4be0-bea9-dc79b274596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"../../images/faces/face_sample.jpg\"\n",
    "\n",
    "img_cv = cv2.imread(img_path)\n",
    "img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)\n",
    "img = Image.fromarray(img_rgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a59971-f343-481c-b40a-c9d4b1ded06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.title(\"Input Image â€“ face_sample.jpg\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25482179-4610-4b11-be9e-cb9d6130d395",
   "metadata": {},
   "source": [
    "## Preprocess & Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "249aec15-1116-41e8-8840-898e31b0ac6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "input_tensor = transform(img).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c161ecc8-531f-4f53-8d02-2fa0f660d3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsion\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\tsion\\AppData\\Roaming\\Python\\Python312\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\tsion/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 44.7M/44.7M [01:25<00:00, 551kB/s] \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = models.resnet18(pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "input_tensor = input_tensor.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_tensor)\n",
    "    probabilities = torch.nn.functional.softmax(outputs[0], dim=0)\n",
    "    top5_prob, top5_idx = torch.topk(probabilities, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8f02a-9c4c-4685-b1ee-60ab6c4e9715",
   "metadata": {},
   "source": [
    "## Load Labels & Display Top-5 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "059ed51a-f7fe-4bdf-9b83-ef573dd55fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bikini: 0.2516\n",
      "wig: 0.1464\n",
      "maillot: 0.0608\n",
      "bonnet: 0.0444\n",
      "brassiere: 0.0348\n"
     ]
    }
   ],
   "source": [
    "labels_url = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
    "labels = requests.get(labels_url).text.strip().split(\"\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"{labels[top5_idx[i]]}: {top5_prob[i].item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f45292-7a3f-42e5-9332-48ead225141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## âœ… Result & Reflection\n",
    "\n",
    "The ResNet-18 model successfully classified the input image and returned the top-5 predictions with confidence scores. This demonstrates the power of CNNs in extracting hierarchical features and making accurate predictions on real-world data.\n",
    "\n",
    "Compared to classical methods (Haar, HOG), deep learning offers:\n",
    "- End-to-end learning from raw pixels\n",
    "- Robustness to scale, lighting, and occlusion\n",
    "- Transfer learning via pretrained models\n",
    "\n",
    "Future enhancements may include:\n",
    "- Comparing with MobileNetV2 (TensorFlow)\n",
    "- Fine-tuning on a custom dataset\n",
    "- Visualizing intermediate feature maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caef0642-3cd1-4d9c-b3ec-6a264f99a52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a41c13-620d-4f5b-b1cc-ad73aafc91ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a75326-20d4-4202-b2ff-7b4cce8861f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4731942f-d37b-4736-b09f-981d8bae945d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069522ba-87ab-4569-855f-a16057e29a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14bf94-d91f-470e-adda-54d829f0f409",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
